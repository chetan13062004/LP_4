{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa3889e-8340-4808-9849-7c02c6e9d997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words = 183\n",
      "Vocabulary Size = 98\n",
      "\n",
      "Sample training data (context → target):\n",
      "\n",
      "(['the', 'speed', 'transmission', 'is'], 'of')\n",
      "(['speed', 'of', 'is', 'an'], 'transmission')\n",
      "(['of', 'transmission', 'an', 'important'], 'is')\n",
      "(['transmission', 'is', 'important', 'point'], 'an')\n",
      "(['is', 'an', 'point', 'of'], 'important')\n",
      "\n",
      "Context words: ['the', 'speed', 'transmission', 'is']\n",
      "Target word: of\n",
      "\n",
      "Predicted vector (average of context embeddings):\n",
      "[0.6328904  0.71675175 0.72562131 0.72154582 0.61260391]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# a. READ TEXT FILE\n",
    "# ----------------------------------------------------------\n",
    "file_path = \"C:/Users/UMESH/OneDrive/Desktop/LP_4/CBOW(Ass5)-20251107T123932Z-1-001/CBOW(Ass5)/CBOW.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# a. DATA PREPARATION\n",
    "# ----------------------------------------------------------\n",
    "text = text.lower()\n",
    "text = re.sub(r'[^a-z0-9\\s]', '', text)   # remove punctuation\n",
    "words = text.split()\n",
    "\n",
    "print(\"Total Words =\", len(words))\n",
    "\n",
    "# Vocabulary\n",
    "vocab = list(set(words))\n",
    "print(\"Vocabulary Size =\", len(vocab))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# b. GENERATE TRAINING DATA (context → target)\n",
    "# ----------------------------------------------------------\n",
    "window = 2\n",
    "training_data = []\n",
    "\n",
    "for i in range(window, len(words) - window):\n",
    "    context = [words[i - 2], words[i - 1], words[i + 1], words[i + 2]]\n",
    "    target = words[i]\n",
    "    training_data.append((context, target))\n",
    "\n",
    "print(\"\\nSample training data (context → target):\\n\")\n",
    "for i in range(5):\n",
    "    print(training_data[i])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# c. SIMULATED TRAINING (random embeddings)\n",
    "# ----------------------------------------------------------\n",
    "np.random.seed(0)\n",
    "embeddings = {w: np.random.rand(5) for w in vocab}   # 5-d embedding\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# d. OUTPUT – average context embedding for first sample\n",
    "# ----------------------------------------------------------\n",
    "sample_context, target = training_data[0]\n",
    "context_vec = np.mean([embeddings[w] for w in sample_context], axis=0)\n",
    "\n",
    "print(\"\\nContext words:\", sample_context)\n",
    "print(\"Target word:\", target)\n",
    "print(\"\\nPredicted vector (average of context embeddings):\")\n",
    "print(context_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd45d6c-021f-471a-8207-7fbd5d048b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703c07e-5e16-4d4b-a317-d23a3789b954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
