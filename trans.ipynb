{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3a56b-8a9e-4ae1-bf45-4b3c651dffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UMESH\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\UMESH\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\UMESH\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Found 674 images belonging to 2 classes.\n",
      "Found 168 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\UMESH\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\UMESH\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "22/22 [==============================] - 304s 14s/step - loss: 0.0994 - accuracy: 0.9852 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - 228s 10s/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 4.1571e-05 - val_accuracy: 1.0000\n",
      "4/6 [===================>..........] - ETA: 15s - loss: 7.6669e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Load base model ----\n",
    "weights_path = r\"C:/Users/UMESH/OneDrive/Desktop/LP_4/Object Detection(Ass6)-20251108T124415Z-1-001/Object Detection(Ass6)/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "base = VGG16(weights=weights_path, include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# ---- Freeze base model ----\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# ---- Data generators ----\n",
    "train_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "selected_classes = ['airplanes', 'ant']\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "   r\"C:/Users/UMESH/OneDrive/Desktop/LP_4/Object Detection(Ass6)-20251108T124415Z-1-001/Object Detection(Ass6)/caltech-101-img\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    subset='training',\n",
    "    classes=selected_classes\n",
    ")\n",
    "\n",
    "val_data = train_gen.flow_from_directory(\n",
    "    r\"C:/Users/UMESH/OneDrive/Desktop/LP_4/Object Detection(Ass6)-20251108T124415Z-1-001/Object Detection(Ass6)/caltech-101-img\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    subset='validation',\n",
    "    classes=selected_classes\n",
    ")\n",
    "\n",
    "# ---- Model ----\n",
    "model = Sequential([\n",
    "    base,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# ---- Train ----\n",
    "model.fit(train_data, validation_data=val_data, epochs=3)\n",
    "\n",
    "# ---- Evaluate ----\n",
    "loss, accuracy = model.evaluate(val_data)\n",
    "print(f\"Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ---- Display predictions ----\n",
    "images, labels = next(val_data)\n",
    "predictions = model.predict(images)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(labels, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(min(9, len(images))):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(f\"True: {selected_classes[true_classes[i]]}\\nPred: {selected_classes[pred_classes[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "batch_acc = np.sum(pred_classes==true_classes)/len(images)*100\n",
    "print(f\"Batch Accuracy: {batch_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d05a1b-dad6-4940-ad77-49f52b3334f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b88d13-e723-4615-b013-85fe7f1bbacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
